{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6234\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(1234)\n",
    "b = tf.constant(5000)\n",
    "\n",
    "add_op = a+b\n",
    "\n",
    "sess = tf.Session()\n",
    "res = sess.run(add_op)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = tf.constant(4)\n",
    "\n",
    "calc1_op = a+b*c\n",
    "calc2_op = (a+b)*c\n",
    "\n",
    "res1 = sess.run(calc1_op)\n",
    "print(res1)\n",
    "res2 = sess.run(calc2_op)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(100)\n",
    "b = tf.constant(50) #상수 정의\n",
    "\n",
    "add_op = a+b\n",
    "\n",
    "v = tf.Variable(0) #변수 v 선언\n",
    "\n",
    "let_op = tf.assign(v, add_op) #변수 v에 add_op의 결과 대입\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) #변수 초기화(메모리에 생성)\n",
    "\n",
    "sess.run(let_op) #계산식 실행\n",
    "print(sess.run(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6 8]\n",
      "[20 40 20 40]\n"
     ]
    }
   ],
   "source": [
    "#placeholder - 정수 자료형 n개를 가진 배열 tf.placeholder(tf.int32, [n])\n",
    "a = tf.placeholder(tf.int32, [4])\n",
    "b = tf.constant(2)\n",
    "x2_op = a*b\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "r1 = sess.run(x2_op, feed_dict = {a:[1, 2, 3, 4]})\n",
    "print(r1)\n",
    "r2 = sess.run(x2_op, feed_dict = {a:[10, 20, 10, 20]})\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 40 50]\n",
      "[100 200]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.int32, [None]) #None으로 지정할 시 입력한 dict 길이만큼 알아서 출력\n",
    "b = tf.constant(10)\n",
    "x10_op = a*b\n",
    "\n",
    "r1 = sess.run(x10_op, feed_dict={a:[1, 2, 3, 4, 5]})\n",
    "print(r1)\n",
    "r2 = sess.run(x10_op, feed_dict={a:[10, 20]})\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "#tensorboard \n",
    "a = tf.constant(20, name = 'a')\n",
    "b = tf.constant(30, name= 'b')\n",
    "mul_op = a*b\n",
    "\n",
    "sess = tf.Session()\n",
    "tw = tf.summary.FileWriter(\"log_dir\", graph=sess.graph)\n",
    "print(sess.run(mul_op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Least square\n",
    "import numpy as np\n",
    "\n",
    "x = [2, 4, 6, 8]\n",
    "y = [81, 93, 91, 97]\n",
    "\n",
    "mx = np.mean(x)\n",
    "my = np.mean(y)\n",
    "\n",
    "divisor = sum([(mx-i)**2 for i in x])\n",
    "\n",
    "def top(x, mx, y, my):\n",
    "    d = 0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i]-mx)*(y[i]-my)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "divided = top(x, mx, y, my)\n",
    "a = divided/divisor\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.0\n"
     ]
    }
   ],
   "source": [
    "b = my-mx*a\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 2, score = 81, predict_score = 82\n",
      "time = 4, score = 93, predict_score = 88\n",
      "time = 6, score = 91, predict_score = 94\n",
      "time = 8, score = 97, predict_score = 100\n",
      "rmse_result:3.3166247903554\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "#임의의 기울기와 절편\n",
    "ab = [3, 76]\n",
    "data = [[2, 81], [4, 93], [6, 91], [8,97]]\n",
    "\n",
    "x = [i[0] for i in data]\n",
    "y = [i[1] for i in data]\n",
    "\n",
    "#임의의 기울기와 저편의 모델로부터 예측값 반환 함수\n",
    "def predict(x):\n",
    "    return ab[0]*x+ab[1]\n",
    "\n",
    "#RMSE 반환 함수\n",
    "def rmse(p, a): #p = 예측, a = 실제\n",
    "    return np.sqrt(((p-a)**2).mean())\n",
    "\n",
    "predict_result = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    predict_result.append(predict(x[i]))\n",
    "    print('time = %.f, score = %.f, predict_score = %.f' %(x[i], y[i], predict_result[i]))\n",
    "\n",
    "\n",
    "#RMSE 반환 함수를 이용하여 최종값 구하기\n",
    "def rmse_val(predict_result, y):\n",
    "    return rmse(np.array(predict_result), np.array(y))\n",
    "\n",
    "print(\"rmse_result:\"+str(rmse_val(predict_result, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE : 30.2139, 기울기: 7.5235, y절편: 80.5984\n",
      "Epoch: 100, RMSE : 2.8860, 기울기: 2.2299, y절편: 79.4181\n",
      "Epoch: 200, RMSE : 2.8826, 기울기: 2.2601, y절편: 79.2379\n",
      "Epoch: 300, RMSE : 2.8815, 기울기: 2.2773, y절편: 79.1353\n",
      "Epoch: 400, RMSE : 2.8811, 기울기: 2.2871, y절편: 79.0770\n",
      "Epoch: 500, RMSE : 2.8810, 기울기: 2.2927, y절편: 79.0438\n",
      "Epoch: 600, RMSE : 2.8810, 기울기: 2.2958, y절편: 79.0249\n",
      "Epoch: 700, RMSE : 2.8810, 기울기: 2.2976, y절편: 79.0142\n",
      "Epoch: 800, RMSE : 2.8810, 기울기: 2.2987, y절편: 79.0081\n",
      "Epoch: 900, RMSE : 2.8810, 기울기: 2.2992, y절편: 79.0046\n",
      "Epoch: 1000, RMSE : 2.8810, 기울기: 2.2996, y절편: 79.0026\n",
      "Epoch: 1100, RMSE : 2.8810, 기울기: 2.2998, y절편: 79.0015\n",
      "Epoch: 1200, RMSE : 2.8810, 기울기: 2.2999, y절편: 79.0008\n",
      "Epoch: 1300, RMSE : 2.8810, 기울기: 2.2999, y절편: 79.0005\n",
      "Epoch: 1400, RMSE : 2.8810, 기울기: 2.3000, y절편: 79.0003\n",
      "Epoch: 1500, RMSE : 2.8810, 기울기: 2.3000, y절편: 79.0002\n",
      "Epoch: 1600, RMSE : 2.8810, 기울기: 2.3000, y절편: 79.0001\n",
      "Epoch: 1700, RMSE : 2.8810, 기울기: 2.3000, y절편: 79.0001\n",
      "Epoch: 1800, RMSE : 2.8810, 기울기: 2.3000, y절편: 79.0000\n",
      "Epoch: 1900, RMSE : 2.8810, 기울기: 2.3000, y절편: 79.0000\n",
      "Epoch: 2000, RMSE : 2.8810, 기울기: 2.3000, y절편: 79.0000\n"
     ]
    }
   ],
   "source": [
    "#gradient decent(경사하강법) 학습률 지정\n",
    "import tensorflow as tf\n",
    "\n",
    "data = [[2, 81], [4, 93], [6, 91], [8,97]]\n",
    "\n",
    "x_data = [i[0] for i in data]\n",
    "y_data = [i[1] for i in data]\n",
    "\n",
    "#기울기, y절편 임의 지정(변수)\n",
    "a = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100, dtype=tf.float64, seed=0))\n",
    "y = a*x_data+b\n",
    "\n",
    "#오차계산(RMSE)\n",
    "\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(y-y_data)))\n",
    "\n",
    "#학습률\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "#오차 최소\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_descent)\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE : %.4f, 기울기: %.4f, y절편: %.4f\"\n",
    "                  %(step, sess.run(rmse), sess.run(a), sess.run(b)))\n",
    "\n",
    "#Epoch, 입력값에 대해 몇번 반복하였는지를 나타내는 용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE : 49.1842, 기울기1: 7.5270, 기울기2: 7.8160 y절편: 80.5980\n",
      "Epoch: 100, RMSE : 1.8368, 기울기1: 1.1306, 기울기2: 2.1316 y절편: 78.5119\n",
      "Epoch: 200, RMSE : 1.8370, 기울기1: 1.1879, 기울기2: 2.1487 y절편: 78.1057\n",
      "Epoch: 300, RMSE : 1.8370, 기울기1: 1.2122, 기울기2: 2.1571 y절편: 77.9352\n",
      "Epoch: 400, RMSE : 1.8370, 기울기1: 1.2226, 기울기2: 2.1607 y절편: 77.8636\n",
      "Epoch: 500, RMSE : 1.8370, 기울기1: 1.2269, 기울기2: 2.1622 y절편: 77.8335\n",
      "Epoch: 600, RMSE : 1.8370, 기울기1: 1.2288, 기울기2: 2.1628 y절편: 77.8208\n",
      "Epoch: 700, RMSE : 1.8370, 기울기1: 1.2295, 기울기2: 2.1631 y절편: 77.8155\n",
      "Epoch: 800, RMSE : 1.8370, 기울기1: 1.2299, 기울기2: 2.1632 y절편: 77.8133\n",
      "Epoch: 900, RMSE : 1.8370, 기울기1: 1.2300, 기울기2: 2.1632 y절편: 77.8124\n",
      "Epoch: 1000, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8120\n",
      "Epoch: 1100, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8118\n",
      "Epoch: 1200, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8117\n",
      "Epoch: 1300, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8117\n",
      "Epoch: 1400, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8117\n",
      "Epoch: 1500, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8117\n",
      "Epoch: 1600, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8117\n",
      "Epoch: 1700, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8117\n",
      "Epoch: 1800, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8117\n",
      "Epoch: 1900, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8117\n",
      "Epoch: 2000, RMSE : 1.8370, 기울기1: 1.2301, 기울기2: 2.1633 y절편: 77.8117\n"
     ]
    }
   ],
   "source": [
    "#gradient decent(경사하강법) 학습률 지정 다중선형회귀\n",
    "import tensorflow as tf\n",
    "\n",
    "data = [[2, 81, 0], [4, 93, 4], [6, 91, 2], [8,97, 3]]\n",
    "\n",
    "x1_data = [i[0] for i in data]\n",
    "x2_data = [i[2] for i in data]\n",
    "y_data = [i[1] for i in data]\n",
    "\n",
    "\n",
    "#기울기, y절편 임의 지정(변수)\n",
    "a1 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "a2 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100, dtype=tf.float64, seed=0))\n",
    "y = a1*x1_data+ a2*x2_data + b\n",
    "\n",
    "#오차계산(RMSE)\n",
    "\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(y-y_data)))\n",
    "\n",
    "#학습률\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "#오차 최소\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_descent)\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE : %.4f, 기울기1: %.4f, 기울기2: %.4f y절편: %.4f\"\n",
    "                  %(step, sess.run(rmse), sess.run(a1), sess.run(a2), sess.run(b)))\n",
    "\n",
    "#Epoch, 입력값에 대해 몇번 반복하였는지를 나타내는 용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch: 0, loss : 1.2676, 기울기: 0.1849, y절편: -0.4334\n",
      "Epoch: 1000, loss : 0.0557, 기울기: -1.6009, y절편: 11.0208\n",
      "Epoch: 2000, loss : 0.0361, 기울기: -2.0366, y절편: 14.0909\n",
      "Epoch: 3000, loss : 0.0269, 기울기: -2.3380, y절편: 16.2087\n",
      "Epoch: 4000, loss : 0.0214, 기울기: -2.5708, y절편: 17.8417\n",
      "Epoch: 5000, loss : 0.0178, 기울기: -2.7607, y절편: 19.1734\n",
      "Epoch: 6000, loss : 0.0152, 기울기: -2.9211, y절편: 20.2982\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "data = [[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]]\n",
    "\n",
    "x_data = [i[0] for i in data]\n",
    "y_data = [i[1] for i in data]\n",
    "\n",
    "a = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "b = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "\n",
    "#시그모이드 함수 방정식의 정의\n",
    "y = 1/(1+np.e**(a*x_data+b))\n",
    "\n",
    "loss = -tf.reduce_mean(np.array(y_data)*tf.log(y)+(1-np.array(y_data))*tf.log(1-y))\n",
    "\n",
    "learning_rate = 0.5\n",
    "\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(6001):\n",
    "        sess.run(gradient_descent)\n",
    "        if step % 1000 == 0:\n",
    "            print(\"Epoch: %.f, loss : %.4f, 기울기: %.4f, y절편: %.4f\"\n",
    "                  %(step, sess.run(loss), sess.run(a), sess.run(b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 , loss=3.1340,  기울기 a1=0.6854, 기울기 a2=0.7527, 절편 b= 0.8568\n",
      "Epoch: 500 , loss=0.2225,  기울기 a1=0.8805, 기울기 a2=-0.5021, 절편 b= -3.2281\n",
      "Epoch: 1000 , loss=0.1461,  기울기 a1=0.7465, 기울기 a2=0.0389, 절편 b= -5.0851\n",
      "Epoch: 1500 , loss=0.1080,  기울기 a1=0.5928, 기울기 a2=0.5029, 절편 b= -6.3690\n",
      "Epoch: 2000 , loss=0.0854,  기울기 a1=0.4686, 기울기 a2=0.8699, 절편 b= -7.3555\n",
      "Epoch: 2500 , loss=0.0706,  기울기 a1=0.3729, 기울기 a2=1.1619, 절편 b= -8.1580\n",
      "Epoch: 3000 , loss=0.0602,  기울기 a1=0.2987, 기울기 a2=1.3997, 절편 b= -8.8351\n",
      "Epoch: 3500 , loss=0.0524,  기울기 a1=0.2398, 기울기 a2=1.5984, 절편 b= -9.4208\n",
      "Epoch: 4000 , loss=0.0465,  기울기 a1=0.1917, 기울기 a2=1.7683, 절편 b= -9.9368\n",
      "Epoch: 4500 , loss=0.0417,  기울기 a1=0.1514, 기울기 a2=1.9165, 절편 b= -10.3980\n",
      "Epoch: 5000 , loss=0.0379,  기울기 a1=0.1169, 기울기 a2=2.0478, 절편 b= -10.8148\n"
     ]
    }
   ],
   "source": [
    "#다중입력값 logistic regression\n",
    "\n",
    "x_data = np.array([[2, 3], [4, 3], [6, 4], [8, 6], [10, 7], [12, 8], [14, 7]])\n",
    "y_data = np.array([0, 0, 0, 1, 1, 1, 1]).reshape(7, 1)\n",
    "\n",
    "#입력값을 placeholder에 저장\n",
    "X = tf.placeholder(tf.float64, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float64, shape=[None, 1])\n",
    "\n",
    "#실행할 때마다 동일한 출력(결과)를 얻기 위한 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "a = tf.Variable(tf.random_uniform([2, 1], dtype=tf.float64))\n",
    "#[2, 1]들어오는 값은 2, 나가는 값은 1\n",
    "b = tf.Variable(tf.random_uniform([1], dtype=tf.float64))\n",
    "\n",
    "y = tf.sigmoid(tf.matmul(X, a) + b)\n",
    "\n",
    "loss = -tf.reduce_mean(Y*tf.log(y)+(1-Y)*tf.log(1-y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "predicted = tf.cast(y >0.5, dtype=tf.float64)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float64))\n",
    "\n",
    "#tf.cast() 함수는 형변환(cast) 수행 > 부동소수점형(실수)를 정수형으로 변환할때 소수점 이하 버림 bool(논리) 자료형 으로 변환할때 True = 1, False = 0 반환\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())     # 변수들을 메모리에 생성, 초기화\n",
    "    for step in range(5001):\n",
    "        a_, b_, loss_, _ = sess.run([a, b, loss, gradient_descent], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 500 == 0:\n",
    "            print(\"Epoch: %.f , loss=%.4f,  기울기 a1=%.4f, 기울기 a2=%.4f, 절편 b= %.4f\" % (step,  loss_,  a_[0], a_[1],  b_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력값:(0, 0)출력값:0\n",
      "입력값:(0, 1)출력값:1\n",
      "입력값:(1, 0)출력값:1\n",
      "입력값:(1, 1)출력값:0\n"
     ]
    }
   ],
   "source": [
    "#은닉층으로 좌표평면 왜곡, 시그모이드 함수 사용, XOR문제 해결\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#가중치와 바이어스(편차)\n",
    "w11 = np.array([-2, -2])\n",
    "w12 = np.array([2, 2])\n",
    "\n",
    "w2 = np.array([1, 1])\n",
    "\n",
    "b1 = 3\n",
    "b2 = -1\n",
    "b3 = -1\n",
    "\n",
    "#perceptron\n",
    "def MLP(x, w, b):\n",
    "    y = np.sum(w*x) + b\n",
    "    if y <=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "#NAND게이트\n",
    "def NAND(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w11, b1)\n",
    "\n",
    "#OR게이트\n",
    "def OR(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w12, b2)\n",
    "\n",
    "#AND게이트\n",
    "def AND(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w2, b3)\n",
    "\n",
    "#XOR게이트\n",
    "def XOR(x1, x2):\n",
    "    return AND(NAND(x1, x2), OR(x1, x2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for x in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "        y = XOR(x[0], x[1])\n",
    "        print(\"입력값:\"+str(x)+\"출력값:\"+str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
